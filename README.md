# YouTube 댓글 크롤러

YouTube 동영상에서 댓글과 참여 지표를 추출하는 지능형 무한 스크롤 지원 프로덕션 레디 Python 스크래퍼입니다.

## ✨ 주요 기능

- **스마트 무한 스크롤**: 댓글 로딩이 완료되면 자동으로 감지 (관련 동영상까지 스크롤하지 않음)
- **완전한 참여 데이터**: 좋아요, 답글, 타임스탬프, 크리에이터 상호작용 추출
- **비디오 메타데이터 통합**: CSV의 원본 비디오 데이터와 댓글 결합
- **오류 처리**: 삭제되거나 사용할 수 없는 비디오를 우아하게 처리
- **진행 상황 추적**: 진행 상황 저장 및 상세한 리포팅 제공
- **프로덕션 레디**: 모범 사례를 따르는 깔끔하고 리팩토링된 코드

## 🚀 빠른 시작

1. **의존성 설치**:
   ```bash
   pip install selenium pandas webdriver-manager
   ```

2. **스크래퍼 실행**:
   ```bash
   python youtube_comment_scraper.py your_video_data.csv
   ```

3. **결과 확인**:
   - 댓글은 `comments_data/youtube_comments_YYYYMMDD_HHMMSS.csv`에 저장됩니다
   - 진행 상황은 `progress.json`에서 추적됩니다

## 📊 추출되는 데이터

### 댓글 데이터
- `comment_text`: 댓글 내용
- `author_name`: 댓글 작성자의 표시 이름  
- `upvotes`: 좋아요 수 (엄지 위)
- `reply_count`: 댓글에 대한 답글 수
- `timestamp`: 댓글이 게시된 시간
- `is_pinned`: 크리에이터가 고정했는지 여부
- `is_hearted`: 크리에이터가 하트를 눌렀는지 여부

### 비디오 메타데이터 (CSV에서)
- `video_no`, `video_date`, `channel_name`, `video_title`
- `total_comments`, `total_likes`, `total_views`
- `comment_position`, `scraped_at`

## 📁 프로젝트 구조

```
YoutubeCrawl/
├── youtube_comment_scraper.py  # 메인 스크래퍼 (프로덕션 레디)
├── config.py                   # 설정 파일
├── README.md                   # 문서
├── process_youtube_data.py     # 데이터 처리 유틸리티
├── read_excel.py              # Excel 파일 리더
├── comments_data/             # 출력 디렉토리
├── data/                      # 입력 Excel 파일
├── url_list/                  # 생성된 URL 리스트
├── working_test.csv           # 테스트 데이터셋 (5개 작동 비디오)
├── mini_test.csv              # 최소 테스트 데이터셋 (3개 비디오)
└── top10_test.csv             # 상위 10개 비디오 테스트 데이터셋
```

## ⚙️ 설정

스크래핑 동작을 사용자 정의하려면 `config.py`를 편집하세요:

```python
# 스크래핑 동작
MAX_SCROLL_ATTEMPTS = 30        # 최대 스크롤 시도 횟수
SCROLL_DELAY = 3                # 스크롤 간 지연 시간 (초)
VIDEO_DELAY = 3                 # 비디오 간 지연 시간 (초)

# 브라우저 설정
HEADLESS_MODE = False           # 백그라운드에서 브라우저 실행
DEFAULT_TIMEOUT = 15            # 페이지 로드 타임아웃 (초)
```

## 📈 성능

- **스마트 스크롤링**: 댓글이 끝나면 중단 (관련 비디오가 아닌)
- **빠른 처리**: 100+ 댓글이 있는 5개 비디오에 대해 약 2-3분
- **메모리 효율적**: 메모리 문제를 피하기 위해 비디오를 순차적으로 처리
- **강력한 오류 처리**: 개별 비디오가 실패해도 처리를 계속

## 🔧 사용 예시

### 기본 사용법
```bash
python youtube_comment_scraper.py ./data/merged_youtube_data.csv
```

### 작은 데이터셋으로 테스트
```bash
python youtube_comment_scraper.py working_test.csv
```

### 특정 비디오 세트 처리
```bash
python youtube_comment_scraper.py mini_test.csv
```

## 📋 CSV 입력 형식

CSV 파일에는 다음 컬럼들이 포함되어야 합니다:
- `URL`: YouTube 비디오 URL
- `제목`: 비디오 제목 (한국어)
- `채널명`: 채널 이름 (한국어)
- `날짜`: 업로드 날짜 (한국어)
- `댓글 수`: 댓글 수 (한국어)
- `좋아요 수`: 좋아요 수 (한국어)
- `조회수`: 조회수 (한국어)

## 🎯 스마트 스크롤 알고리즘

스크래퍼는 다음과 같은 지능형 스크롤링 알고리즘을 사용합니다:

1. **댓글에 집중**: 페이지 높이가 아닌 실제 댓글 요소를 추적
2. **완료 감지**: 여러 시도 후 새 댓글이 로드되지 않으면 중단
3. **관련 비디오 회피**: 스크롤이 관련 콘텐츠에 도달하면 감지
4. **최종 시도**: 중단하기 전에 한 번의 적극적인 스크롤 수행
5. **진행 로깅**: 실시간 댓글 로딩 진행 상황 표시

## 📊 출력 예시

```
📊 YOUTUBE 댓글 스크래핑 요약:
📁 출력 파일: comments_data/youtube_comments_20231215_143022.csv
💬 총 댓글 수: 136
🎥 처리된 비디오: 5
✅ 성공한 비디오: 5
❌ 실패한 비디오: 0
👥 고유 작성자: 121
👍 총 좋아요: 540
💭 답글이 있는 댓글: 23
📈 비디오당 평균 댓글 수: 27.2
```

## 🛠️ 개발

코드베이스는 클린 코드 원칙을 따릅니다:

- **단일 책임**: 각 메서드는 명확하고 집중된 목적을 가짐
- **오류 처리**: 로깅과 함께 포괄적인 예외 처리
- **설정**: `config.py`에서 중앙 집중식 설정
- **문서화**: 명확한 독스트링과 주석
- **검증**: 시작 시 설정 검증

## 📝 로깅

- 모든 활동은 `scraper.log`에 기록됩니다
- 진행 상황은 복구를 위해 `progress.json`에 저장됩니다
- 실패한 비디오는 상세한 오류 정보와 함께 추적됩니다
- 실시간 콘솔 출력으로 스크래핑 진행 상황을 표시합니다

## 🔍 문제 해결

### 비디오를 찾을 수 없음
- 비디오 URL이 올바르고 접근 가능한지 확인
- 일부 비디오는 지역 제한이 있거나 삭제되었을 수 있음

### 느린 성능
- 더 나은 안정성을 위해 config에서 `SCROLL_DELAY` 증가
- 헤드리스 모드에서 실행: `HEADLESS_MODE = True` 설정

### 메모리 문제
- 더 작은 비디오 배치 처리
- 대용량 데이터셋의 경우 주기적으로 스크래퍼 재시작

## 🚀 실행 스크립트 사용법

편리한 실행을 위해 `run_scraper.sh` 스크립트를 제공합니다:

```bash
# 실행 권한 부여
chmod +x run_scraper.sh

# 다양한 옵션으로 실행
./run_scraper.sh mini        # 미니 테스트 (3개 비디오)
./run_scraper.sh test        # 작업 테스트 (5개 비디오)
./run_scraper.sh top10       # 상위 10개 테스트 (10개 비디오)
./run_scraper.sh full        # 전체 데이터셋 (5,363개 비디오)
./run_scraper.sh background  # 백그라운드에서 전체 데이터셋 실행
```

### 백그라운드 실행 모니터링
```bash
# 진행 상황 모니터링
tail -f scraping_output_YYYYMMDD_HHMMSS.log

# 프로세스 확인
ps aux | grep python

# 프로세스 중단 (필요시)
kill [PID]
```

## 📊 데이터 처리 파이프라인

### 1단계: 데이터 입력
- CSV 파일에서 비디오 메타데이터 로드
- 한국어 컬럼명 지원 (제목, 채널명, 날짜, 댓글 수, 좋아요 수, 조회수)

### 2단계: 필터링
- 설정된 임계값에 따라 비디오 필터링
- 최소 댓글 수, 조회수, 좋아요 수 기준 적용

### 3단계: 웹 드라이버 설정
- Chrome WebDriver 자동 설정
- 성능 최적화 옵션 적용
- 헤드리스 모드 지원

### 4단계: 비디오별 처리
- 각 비디오 URL 접근
- 비디오 가용성 확인
- 댓글 섹션으로 스크롤

### 5단계: 스마트 댓글 추출
- 지능형 무한 스크롤 실행
- 댓글 요소 실시간 추적
- 관련 비디오 영역 감지 시 중단

### 6단계: 데이터 결합 및 저장
- 댓글 데이터와 비디오 메타데이터 결합
- CSV 형식으로 결과 저장
- 진행 상황 및 통계 리포트 생성

## 📈 성능 최적화 팁

### 대용량 데이터셋 처리
- 배치 단위로 처리하여 메모리 사용량 관리
- 정기적인 진행 상황 저장으로 복구 가능
- 실패한 비디오 건너뛰고 계속 진행

### 안정성 향상
- 네트워크 지연을 고려한 적절한 대기 시간 설정
- 예외 상황에 대한 포괄적인 오류 처리
- 상세한 로깅으로 문제 진단 지원

## 📜 라이선스 및 주의사항

이 프로젝트는 교육 및 연구 목적으로 제작되었습니다. YouTube의 서비스 약관과 속도 제한을 준수해 주시기 바랍니다.

### 사용 시 주의사항
- 적절한 지연 시간을 설정하여 서버 부하 방지
- 대량 스크래핑 시 YouTube 정책 확인
- 개인정보 보호 및 데이터 사용 규정 준수 